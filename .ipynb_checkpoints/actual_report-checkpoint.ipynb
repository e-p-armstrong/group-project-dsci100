{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf633a9-30fc-402f-bfed-4546ed31c49f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting Heart Disease Based On Physical Characteristics of Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011bf46-9235-485e-a640-6e862d490996",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Heart disease is an often-lethal condition, and being able to accurately predict if patients have it, based on easy-to-observe qualities, would allow for quicker action from doctors and better patient outcomes. So here we ask the question: is it possible to predict whether a patient has heart disease based on a set of measurable factors? To build a model that could answer this, we used the publicly-available heart disease dataset donated by the Hungarian Institute of Cardiology, the University Hospitals of Zurich and Basel, the V. A. Medical Center of Long Beach, and the Cleveland Clinic Foundation. Each row in this dataset represents a patient, and the columns store physical, health-related information about each patient — such as their age, sex, type of chest pain, and resting blood pressure. There are 14 variables in total. The column we are attempting to predict has values of either “true” or “false”, indicating whether a patient has some variety of heart disease. The dataset contains four databases, each with around 100 to 300 patients, donated by institutions in Switzerland, Hungary, and two locations in America. We trained and tested our model on data from all of the databases, as this gives us a larger sample size, and an additional variable to work with (region). This brings the total number of columns in our dataset to 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfea2c2-83ef-477e-9e24-368fdd206d86",
   "metadata": {},
   "source": [
    "## Preliminary Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59612134-9de0-401c-897e-e9b099955e5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports\n",
    "In this cell we import a number of neccessary libraries, whose functions we will be using frequently in the analysis. Of note are tidyverse and tidymodels. We also set the seed of the program so that running it multiple times will produce consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a9c354-41d0-4f63-b4ff-4cf62e85d59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.1     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Dig deeper into tidy modeling with R at \u001b[32mhttps://www.tmwr.org\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "set.seed(1048596) # specific seed number picked because Steins;Gate references automatically make the code work better because of convergence or something "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f282247-bb0a-42b6-8f3d-85c2f53e10eb",
   "metadata": {},
   "source": [
    "### Reading and tidying the data: to start with, a function\n",
    "\n",
    "We have a number of datasets that we're working with in this analysis: data on heart disease from health centers of Cleveland, Long Beach (Veteran's Affairs), Hungary, and Switzerland. For each of them we want to first load them and then \"tidy\" them — in this case, this means we want to select a few relevant columns out of the whole bunch, remove columns with NA values (cases where key data wasn't recorded, these points do not work well with numbers-based classification algorithms like KNN), and also change the types of some columns that are loaded in as character vectors to numeric. A key coding concept is DRY — Don't Repeat Yourself — and so we write a function which performs some of the more repetitive tasks on a freshly-loaded dataframe for us. This function descriptively renames the initially-nameless columns, assigns a region to loaded observations, changes \"num\" from a numeric to a character vector (which makes more sense for a factor, and is also easier interpret), and selects the specific columns we want for the purposes of this analysis. \n",
    "\n",
    "We picked the columns we did because \n",
    "## !!!!!!!**DOMAIN ANALYSIS WOULD GO HERE**!!!!!!!\n",
    "Also note to self: change num to has_heart_disease or something, num makes absolutely 0 sense after it was converted to a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67cac22c-281b-48a5-a7aa-4ef6ebbceeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tidy up each of the separate datasets\n",
    "# Discovery: in the non-cleveland sets, many of the more obscure columns have missing values in some rows. If you filter out all the rows that don't have missing values anywhere you sometimes end up with none from that set.\n",
    "# TODO: get domain knowledge, use to find best predictors to use\n",
    "\n",
    "tidy_heart_data <- function(df, region=\"\") {\n",
    "    colnames(df) <- column_names\n",
    "    df <- mutate(df, region=region) #cleveland\n",
    "    df$num<-ifelse(df$num==0,\"true\",\"false\")\n",
    "    if (region != \"\") {\n",
    "        df <- mutate(df, region=as.factor(region))\n",
    "        }\n",
    "    return (df |> select(num,\n",
    "                         age, #\n",
    "                         region,\n",
    "                         cp, #\n",
    "                         sex,#\n",
    "                         thalach, #\n",
    "                         trestbps, #\n",
    "                         chol, #\n",
    "                         fbs, #\n",
    "                         restecg, #\n",
    "                         exang, #\n",
    "                         oldpeak, #\n",
    "                         \n",
    "                        ) |> \n",
    "                          filter(cp!=\"?\",\n",
    "                                 sex!=\"?\",\n",
    "                                 thalach!=\"?\",\n",
    "                                 trestbps!=\"?\",\n",
    "                                 trestbps!=\"0\",\n",
    "                                 chol!=\"?\",\n",
    "                                 fbs!=\"?\",\n",
    "                                 restecg!=\"?\",\n",
    "                                 exang!=\"?\",\n",
    "                                 oldpeak!=\"?\",)|>\n",
    "                                 \n",
    "                        \n",
    "                          mutate(region=as.factor(region),\n",
    "                                 sex=as.numeric(sex),\n",
    "                                 cp=as.numeric(cp),\n",
    "                                 thalach=as.numeric(thalach),\n",
    "                                 trestbps=as.numeric(trestbps),\n",
    "                                 chol=as.numeric(chol),\n",
    "                                 fbs=as.numeric(fbs),\n",
    "                                 restecg=as.numeric(restecg),\n",
    "                                 exang=as.numeric(exang),\n",
    "                                 oldpeak=as.numeric(oldpeak),\n",
    "                                 # slope=as.numeric(slope),\n",
    "                                 # ca=as.numeric(ca),\n",
    "                                 # thal=as.numeric(thal),\n",
    "                                 num = as.factor(num)))\n",
    "    }\n",
    "\n",
    "column_names <-c(\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c4fbf-2c21-4478-b28b-aa12f19d7c18",
   "metadata": {},
   "source": [
    "### Reading and tidying the data: Calling the function\n",
    "The cells below each call the above function with the freshly-loaded dataframe, and the region name corresponding to the loaded region. \n",
    "\n",
    "#### Cleveland \n",
    "In the case directly below, we load and tidy the data from the Cleveland Clinic Foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ef0db6-4345-4d2f-aec0-f8463593884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m303\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): X12, X13\n",
      "\u001b[32mdbl\u001b[39m (12): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 303 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>true </td><td>63</td><td>C</td><td>1</td><td>1</td><td>150</td><td>145</td><td>233</td><td>1</td><td>2</td><td>0</td><td>2.3</td></tr>\n",
       "\t<tr><td>false</td><td>67</td><td>C</td><td>4</td><td>1</td><td>108</td><td>160</td><td>286</td><td>0</td><td>2</td><td>1</td><td>1.5</td></tr>\n",
       "\t<tr><td>false</td><td>67</td><td>C</td><td>4</td><td>1</td><td>129</td><td>120</td><td>229</td><td>0</td><td>2</td><td>1</td><td>2.6</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>false</td><td>57</td><td>C</td><td>4</td><td>1</td><td>115</td><td>130</td><td>131</td><td>0</td><td>0</td><td>1</td><td>1.2</td></tr>\n",
       "\t<tr><td>false</td><td>57</td><td>C</td><td>2</td><td>0</td><td>174</td><td>130</td><td>236</td><td>0</td><td>2</td><td>0</td><td>0.0</td></tr>\n",
       "\t<tr><td>true </td><td>38</td><td>C</td><td>3</td><td>1</td><td>173</td><td>138</td><td>175</td><td>0</td><td>0</td><td>0</td><td>0.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 303 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t true  & 63 & C & 1 & 1 & 150 & 145 & 233 & 1 & 2 & 0 & 2.3\\\\\n",
       "\t false & 67 & C & 4 & 1 & 108 & 160 & 286 & 0 & 2 & 1 & 1.5\\\\\n",
       "\t false & 67 & C & 4 & 1 & 129 & 120 & 229 & 0 & 2 & 1 & 2.6\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t false & 57 & C & 4 & 1 & 115 & 130 & 131 & 0 & 0 & 1 & 1.2\\\\\n",
       "\t false & 57 & C & 2 & 0 & 174 & 130 & 236 & 0 & 2 & 0 & 0.0\\\\\n",
       "\t true  & 38 & C & 3 & 1 & 173 & 138 & 175 & 0 & 0 & 0 & 0.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 303 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| true  | 63 | C | 1 | 1 | 150 | 145 | 233 | 1 | 2 | 0 | 2.3 |\n",
       "| false | 67 | C | 4 | 1 | 108 | 160 | 286 | 0 | 2 | 1 | 1.5 |\n",
       "| false | 67 | C | 4 | 1 | 129 | 120 | 229 | 0 | 2 | 1 | 2.6 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| false | 57 | C | 4 | 1 | 115 | 130 | 131 | 0 | 0 | 1 | 1.2 |\n",
       "| false | 57 | C | 2 | 0 | 174 | 130 | 236 | 0 | 2 | 0 | 0.0 |\n",
       "| true  | 38 | C | 3 | 1 | 173 | 138 | 175 | 0 | 0 | 0 | 0.0 |\n",
       "\n"
      ],
      "text/plain": [
       "    num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1   true  63  C      1  1   150     145      233  1   2       0     2.3    \n",
       "2   false 67  C      4  1   108     160      286  0   2       1     1.5    \n",
       "3   false 67  C      4  1   129     120      229  0   2       1     2.6    \n",
       "⋮   ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "301 false 57  C      4  1   115     130      131  0   0       1     1.2    \n",
       "302 false 57  C      2  0   174     130      236  0   2       0     0.0    \n",
       "303 true  38  C      3  1   173     138      175  0   0       0     0.0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleveland_data<- read_delim(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",\n",
    "                         col_name = FALSE)\n",
    "cleveland_data <- tidy_heart_data(cleveland_data,\"C\")\n",
    "\n",
    "cleveland_data               \n",
    "# Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e0153-7fb1-40cd-86fe-90cb3c345b71",
   "metadata": {},
   "source": [
    "#### Hungary\n",
    "Next, we load and tidy the data from The University Hospital of Basel. The usefulness of the function we wrote in reducing clutter is already evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35bfc8b-3478-4a34-b0d4-3035cc09149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m294\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): X4, X5, X6, X7, X8, X9, X11, X12, X13\n",
      "\u001b[32mdbl\u001b[39m (5): X1, X2, X3, X10, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 261 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>true</td><td>28</td><td>H</td><td>2</td><td>1</td><td>185</td><td>130</td><td>132</td><td>0</td><td>2</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>true</td><td>29</td><td>H</td><td>2</td><td>1</td><td>160</td><td>120</td><td>243</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>true</td><td>30</td><td>H</td><td>1</td><td>0</td><td>170</td><td>170</td><td>237</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>false</td><td>56</td><td>H</td><td>4</td><td>1</td><td>150</td><td>155</td><td>342</td><td>1</td><td>0</td><td>1</td><td>3</td></tr>\n",
       "\t<tr><td>false</td><td>58</td><td>H</td><td>2</td><td>0</td><td>110</td><td>180</td><td>393</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>false</td><td>65</td><td>H</td><td>4</td><td>1</td><td>115</td><td>130</td><td>275</td><td>0</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 261 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t true & 28 & H & 2 & 1 & 185 & 130 & 132 & 0 & 2 & 0 & 0\\\\\n",
       "\t true & 29 & H & 2 & 1 & 160 & 120 & 243 & 0 & 0 & 0 & 0\\\\\n",
       "\t true & 30 & H & 1 & 0 & 170 & 170 & 237 & 0 & 1 & 0 & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t false & 56 & H & 4 & 1 & 150 & 155 & 342 & 1 & 0 & 1 & 3\\\\\n",
       "\t false & 58 & H & 2 & 0 & 110 & 180 & 393 & 0 & 0 & 1 & 1\\\\\n",
       "\t false & 65 & H & 4 & 1 & 115 & 130 & 275 & 0 & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 261 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| true | 28 | H | 2 | 1 | 185 | 130 | 132 | 0 | 2 | 0 | 0 |\n",
       "| true | 29 | H | 2 | 1 | 160 | 120 | 243 | 0 | 0 | 0 | 0 |\n",
       "| true | 30 | H | 1 | 0 | 170 | 170 | 237 | 0 | 1 | 0 | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| false | 56 | H | 4 | 1 | 150 | 155 | 342 | 1 | 0 | 1 | 3 |\n",
       "| false | 58 | H | 2 | 0 | 110 | 180 | 393 | 0 | 0 | 1 | 1 |\n",
       "| false | 65 | H | 4 | 1 | 115 | 130 | 275 | 0 | 1 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "    num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1   true  28  H      2  1   185     130      132  0   2       0     0      \n",
       "2   true  29  H      2  1   160     120      243  0   0       0     0      \n",
       "3   true  30  H      1  0   170     170      237  0   1       0     0      \n",
       "⋮   ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "259 false 56  H      4  1   150     155      342  1   0       1     3      \n",
       "260 false 58  H      2  0   110     180      393  0   0       1     1      \n",
       "261 false 65  H      4  1   115     130      275  0   1       1     1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hungarian_data<-read_delim(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\",\n",
    "                          col_name = FALSE)\n",
    "hungarian_data <- tidy_heart_data(hungarian_data,\"H\")\n",
    "hungarian_data\n",
    "# Table 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a2a7c-0fad-4559-bfbc-a7e9280bdf65",
   "metadata": {},
   "source": [
    "#### Switzerland\n",
    "Here we perform the same procedure for Switzerland. Note the size of this table is much smaller than the rest of the ones we have loaded so far: not only is it the smallest of the datasets we have, coming in around 130 rows, but it also includes many missing values, which means this small size gets shrunk down even further after we process it. This will have ramifications for later parts of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e0317b-2e9e-448b-a8f4-df1c8a947517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m123\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): X4, X6, X7, X8, X9, X10, X11, X12, X13\n",
      "\u001b[32mdbl\u001b[39m (5): X1, X2, X3, X5, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 46 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>false</td><td>38</td><td>S</td><td>4</td><td>0</td><td>156</td><td>110</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>38</td><td>S</td><td>3</td><td>1</td><td>128</td><td>115</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>42</td><td>S</td><td>4</td><td>1</td><td> 99</td><td>145</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>false</td><td>70</td><td>S</td><td>4</td><td>1</td><td> 92</td><td>115</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>70</td><td>S</td><td>4</td><td>1</td><td>157</td><td>140</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2</td></tr>\n",
       "\t<tr><td>false</td><td>73</td><td>S</td><td>3</td><td>0</td><td>121</td><td>160</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 46 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t false & 38 & S & 4 & 0 & 156 & 110 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t false & 38 & S & 3 & 1 & 128 & 115 & 0 & 0 & 0 & 1 & 0\\\\\n",
       "\t false & 42 & S & 4 & 1 &  99 & 145 & 0 & 0 & 0 & 1 & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t false & 70 & S & 4 & 1 &  92 & 115 & 0 & 0 & 1 & 1 & 0\\\\\n",
       "\t false & 70 & S & 4 & 1 & 157 & 140 & 0 & 1 & 0 & 1 & 2\\\\\n",
       "\t false & 73 & S & 3 & 0 & 121 & 160 & 0 & 0 & 1 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 46 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| false | 38 | S | 4 | 0 | 156 | 110 | 0 | 0 | 0 | 0 | 0 |\n",
       "| false | 38 | S | 3 | 1 | 128 | 115 | 0 | 0 | 0 | 1 | 0 |\n",
       "| false | 42 | S | 4 | 1 |  99 | 145 | 0 | 0 | 0 | 1 | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| false | 70 | S | 4 | 1 |  92 | 115 | 0 | 0 | 1 | 1 | 0 |\n",
       "| false | 70 | S | 4 | 1 | 157 | 140 | 0 | 1 | 0 | 1 | 2 |\n",
       "| false | 73 | S | 3 | 0 | 121 | 160 | 0 | 0 | 1 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "   num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1  false 38  S      4  0   156     110      0    0   0       0     0      \n",
       "2  false 38  S      3  1   128     115      0    0   0       1     0      \n",
       "3  false 42  S      4  1    99     145      0    0   0       1     0      \n",
       "⋮  ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "44 false 70  S      4  1    92     115      0    0   1       1     0      \n",
       "45 false 70  S      4  1   157     140      0    1   0       1     2      \n",
       "46 false 73  S      3  0   121     160      0    0   1       0     0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "switzerland_data<-read_delim(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data\",\n",
    "                            col_name = FALSE)\n",
    "switzerland_data <- tidy_heart_data(switzerland_data,\"S\")\n",
    "switzerland_data\n",
    "# Table 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921465d5-17fd-4590-8baf-7a8840cb4db1",
   "metadata": {},
   "source": [
    "#### VA Long Beach\n",
    "We call the function we wrote earlier to tidy the data from the V. A. Medical Center of Long Beach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d28ba2-33b7-4266-858b-ed8a630403a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m200\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): X4, X5, X6, X8, X9, X10, X11, X12, X13\n",
      "\u001b[32mdbl\u001b[39m (5): X1, X2, X3, X7, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 129 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>false</td><td>63</td><td>VA</td><td>4</td><td>1</td><td>112</td><td>140</td><td>260</td><td>0</td><td>1</td><td>1</td><td>3.0</td></tr>\n",
       "\t<tr><td>true </td><td>44</td><td>VA</td><td>4</td><td>1</td><td>127</td><td>130</td><td>209</td><td>0</td><td>1</td><td>0</td><td>0.0</td></tr>\n",
       "\t<tr><td>false</td><td>60</td><td>VA</td><td>4</td><td>1</td><td>140</td><td>132</td><td>218</td><td>0</td><td>1</td><td>1</td><td>1.5</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>false</td><td>54</td><td>VA</td><td>4</td><td>0</td><td>154</td><td>127</td><td>333</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>55</td><td>VA</td><td>4</td><td>1</td><td>100</td><td>122</td><td>223</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>62</td><td>VA</td><td>2</td><td>1</td><td> 93</td><td>120</td><td>254</td><td>0</td><td>2</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 129 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t false & 63 & VA & 4 & 1 & 112 & 140 & 260 & 0 & 1 & 1 & 3.0\\\\\n",
       "\t true  & 44 & VA & 4 & 1 & 127 & 130 & 209 & 0 & 1 & 0 & 0.0\\\\\n",
       "\t false & 60 & VA & 4 & 1 & 140 & 132 & 218 & 0 & 1 & 1 & 1.5\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t false & 54 & VA & 4 & 0 & 154 & 127 & 333 & 1 & 1 & 0 & 0\\\\\n",
       "\t false & 55 & VA & 4 & 1 & 100 & 122 & 223 & 1 & 1 & 0 & 0\\\\\n",
       "\t false & 62 & VA & 2 & 1 &  93 & 120 & 254 & 0 & 2 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 129 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| false | 63 | VA | 4 | 1 | 112 | 140 | 260 | 0 | 1 | 1 | 3.0 |\n",
       "| true  | 44 | VA | 4 | 1 | 127 | 130 | 209 | 0 | 1 | 0 | 0.0 |\n",
       "| false | 60 | VA | 4 | 1 | 140 | 132 | 218 | 0 | 1 | 1 | 1.5 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| false | 54 | VA | 4 | 0 | 154 | 127 | 333 | 1 | 1 | 0 | 0 |\n",
       "| false | 55 | VA | 4 | 1 | 100 | 122 | 223 | 1 | 1 | 0 | 0 |\n",
       "| false | 62 | VA | 2 | 1 |  93 | 120 | 254 | 0 | 2 | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "    num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1   false 63  VA     4  1   112     140      260  0   1       1     3.0    \n",
       "2   true  44  VA     4  1   127     130      209  0   1       0     0.0    \n",
       "3   false 60  VA     4  1   140     132      218  0   1       1     1.5    \n",
       "⋮   ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "127 false 54  VA     4  0   154     127      333  1   1       0     0      \n",
       "128 false 55  VA     4  1   100     122      223  1   1       0     0      \n",
       "129 false 62  VA     2  1    93     120      254  0   2       1     0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "va_data<-read_delim(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.va.data\",\n",
    "                   col_name = FALSE)\n",
    "va_data <- tidy_heart_data(va_data,\"VA\")\n",
    "va_data\n",
    "# Table 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c1647-6258-44ff-87ee-8c980a5f17fe",
   "metadata": {},
   "source": [
    "#### Creating the combined dataset\n",
    "\n",
    "In this cell we combine all the data from earlier into a larger, super-dataset. This is so that we can analyze the accuracy of knn on each region separately, and then each region together, to see which is more accurate; it gives us more options to explore during our analysis. This is also why we appended a \"region\" column to each dataset — this hardly would have made sense if we were keeping them separate the entire time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e2f851-6006-4610-8485-92c6f65a3185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 739 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>true </td><td>63</td><td>C</td><td>1</td><td>1</td><td>150</td><td>145</td><td>233</td><td>1</td><td>2</td><td>0</td><td>2.3</td></tr>\n",
       "\t<tr><td>false</td><td>67</td><td>C</td><td>4</td><td>1</td><td>108</td><td>160</td><td>286</td><td>0</td><td>2</td><td>1</td><td>1.5</td></tr>\n",
       "\t<tr><td>false</td><td>67</td><td>C</td><td>4</td><td>1</td><td>129</td><td>120</td><td>229</td><td>0</td><td>2</td><td>1</td><td>2.6</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>false</td><td>54</td><td>VA</td><td>4</td><td>0</td><td>154</td><td>127</td><td>333</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>55</td><td>VA</td><td>4</td><td>1</td><td>100</td><td>122</td><td>223</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>false</td><td>62</td><td>VA</td><td>2</td><td>1</td><td> 93</td><td>120</td><td>254</td><td>0</td><td>2</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 739 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t true  & 63 & C & 1 & 1 & 150 & 145 & 233 & 1 & 2 & 0 & 2.3\\\\\n",
       "\t false & 67 & C & 4 & 1 & 108 & 160 & 286 & 0 & 2 & 1 & 1.5\\\\\n",
       "\t false & 67 & C & 4 & 1 & 129 & 120 & 229 & 0 & 2 & 1 & 2.6\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t false & 54 & VA & 4 & 0 & 154 & 127 & 333 & 1 & 1 & 0 & 0\\\\\n",
       "\t false & 55 & VA & 4 & 1 & 100 & 122 & 223 & 1 & 1 & 0 & 0\\\\\n",
       "\t false & 62 & VA & 2 & 1 &  93 & 120 & 254 & 0 & 2 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 739 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| true  | 63 | C | 1 | 1 | 150 | 145 | 233 | 1 | 2 | 0 | 2.3 |\n",
       "| false | 67 | C | 4 | 1 | 108 | 160 | 286 | 0 | 2 | 1 | 1.5 |\n",
       "| false | 67 | C | 4 | 1 | 129 | 120 | 229 | 0 | 2 | 1 | 2.6 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| false | 54 | VA | 4 | 0 | 154 | 127 | 333 | 1 | 1 | 0 | 0 |\n",
       "| false | 55 | VA | 4 | 1 | 100 | 122 | 223 | 1 | 1 | 0 | 0 |\n",
       "| false | 62 | VA | 2 | 1 |  93 | 120 | 254 | 0 | 2 | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "    num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1   true  63  C      1  1   150     145      233  1   2       0     2.3    \n",
       "2   false 67  C      4  1   108     160      286  0   2       1     1.5    \n",
       "3   false 67  C      4  1   129     120      229  0   2       1     2.6    \n",
       "⋮   ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "737 false 54  VA     4  0   154     127      333  1   1       0     0      \n",
       "738 false 55  VA     4  1   100     122      223  1   1       0     0      \n",
       "739 false 62  VA     2  1    93     120      254  0   2       1     0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_data <-rbind(cleveland_data,hungarian_data,switzerland_data,va_data)\n",
    "\n",
    "all_data\n",
    "# Table 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39391a-1f8f-4f08-9e09-255d2abca9f5",
   "metadata": {},
   "source": [
    "### Summary of dataset, pre-analysis\n",
    "\n",
    "!EA just copy-paste from the methods section of the proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccba81-1e43-414a-b6fc-410d17f7b837",
   "metadata": {},
   "source": [
    "### Visualization, pre-analysis\n",
    "\n",
    "Here, before performing the analysis itself, we visualize some of the data that we loaded. In figure 1 we used bar graphs to visually represent how many patients in each dataset (after tidying, which makes sense considering that we'll be working with the tidied, filtered dataset) have heart disease, and how many do not. Understanding the ratio will give us a better idea of which variable will dominate the knn algorithm; knowing broadly how many patients there are in each dataset will also partially tell us what values of K might be too high (by virtue of essentially becoming averages). This visualization also has the additional benefit in that it shows us that Switzerland will not be suitable for analysis by itself: it has too few positive cases of heart disease, at one single case, so when stratified into training and testing data one of the two will lack any positive cases. This state of affairs will also cause issues with cross-validation. Therefore, we will not perform analysis on Switzerland seperately throughout this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07bd3cdd-6590-42cb-8d25-8b01e1774adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\n7rgJAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO !EA Visualization of data relevant to the analysis (blocked on domain knowledge, need to know what variables to graph)\n",
    "# Visualization of heart disease by region (will at least explain why we don't use f***ing Switzerland) \n",
    "# Of note for the description: switzerland sucks, Cleveland and Hungary (after being filtered for NA), have more people with heart disease than not.\n",
    "\n",
    "# Figure 1\n",
    "ggplot(all_data, aes(x = num, fill = region)) +\n",
    "    geom_bar() +\n",
    "    facet_grid(rows = vars(region)) +\n",
    "    labs(x = \"Patient has heart disease\", y = \"# of patients (in the region)\", fill = \"Region\", title = \"Switzerland has too few positives for models to be fitted on it alone\") +\n",
    "    scale_fill_discrete(labels = c(\"Cleaveland\", \"Hungary\", \"Switzerland\", \"VA Long Beach\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268145f-8290-48a0-97eb-5119cff5deb1",
   "metadata": {},
   "source": [
    "### Splitting the data into training and testing sets\n",
    "\n",
    "In this cell we split each of our regional datasets (and our combined dataset) into  training and testing sets; the ratio is 75% training, 25% testing, and stratification is done on the \"num\" column, to ensure that both sets have at least a few positive and negative cases each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47070997-bb17-4e5a-b6e7-c35d1475dc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 553 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>num</th><th scope=col>age</th><th scope=col>region</th><th scope=col>cp</th><th scope=col>sex</th><th scope=col>thalach</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>exang</th><th scope=col>oldpeak</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>false</td><td>67</td><td>C</td><td>4</td><td>1</td><td>108</td><td>160</td><td>286</td><td>0</td><td>2</td><td>1</td><td>1.5</td></tr>\n",
       "\t<tr><td>false</td><td>62</td><td>C</td><td>4</td><td>0</td><td>160</td><td>140</td><td>268</td><td>0</td><td>2</td><td>0</td><td>3.6</td></tr>\n",
       "\t<tr><td>false</td><td>63</td><td>C</td><td>4</td><td>1</td><td>147</td><td>130</td><td>254</td><td>0</td><td>2</td><td>0</td><td>1.4</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>true</td><td>57</td><td>VA</td><td>4</td><td>1</td><td> 96</td><td>130</td><td>207</td><td>0</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>true</td><td>68</td><td>VA</td><td>3</td><td>1</td><td>151</td><td>134</td><td>254</td><td>1</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>true</td><td>51</td><td>VA</td><td>4</td><td>0</td><td> 96</td><td>114</td><td>258</td><td>1</td><td>2</td><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 553 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " num & age & region & cp & sex & thalach & trestbps & chol & fbs & restecg & exang & oldpeak\\\\\n",
       " <fct> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t false & 67 & C & 4 & 1 & 108 & 160 & 286 & 0 & 2 & 1 & 1.5\\\\\n",
       "\t false & 62 & C & 4 & 0 & 160 & 140 & 268 & 0 & 2 & 0 & 3.6\\\\\n",
       "\t false & 63 & C & 4 & 1 & 147 & 130 & 254 & 0 & 2 & 0 & 1.4\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t true & 57 & VA & 4 & 1 &  96 & 130 & 207 & 0 & 1 & 1 & 1\\\\\n",
       "\t true & 68 & VA & 3 & 1 & 151 & 134 & 254 & 1 & 0 & 1 & 0\\\\\n",
       "\t true & 51 & VA & 4 & 0 &  96 & 114 & 258 & 1 & 2 & 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 553 × 12\n",
       "\n",
       "| num &lt;fct&gt; | age &lt;dbl&gt; | region &lt;fct&gt; | cp &lt;dbl&gt; | sex &lt;dbl&gt; | thalach &lt;dbl&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| false | 67 | C | 4 | 1 | 108 | 160 | 286 | 0 | 2 | 1 | 1.5 |\n",
       "| false | 62 | C | 4 | 0 | 160 | 140 | 268 | 0 | 2 | 0 | 3.6 |\n",
       "| false | 63 | C | 4 | 1 | 147 | 130 | 254 | 0 | 2 | 0 | 1.4 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| true | 57 | VA | 4 | 1 |  96 | 130 | 207 | 0 | 1 | 1 | 1 |\n",
       "| true | 68 | VA | 3 | 1 | 151 | 134 | 254 | 1 | 0 | 1 | 0 |\n",
       "| true | 51 | VA | 4 | 0 |  96 | 114 | 258 | 1 | 2 | 0 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "    num   age region cp sex thalach trestbps chol fbs restecg exang oldpeak\n",
       "1   false 67  C      4  1   108     160      286  0   2       1     1.5    \n",
       "2   false 62  C      4  0   160     140      268  0   2       0     3.6    \n",
       "3   false 63  C      4  1   147     130      254  0   2       0     1.4    \n",
       "⋮   ⋮     ⋮   ⋮      ⋮  ⋮   ⋮       ⋮        ⋮    ⋮   ⋮       ⋮     ⋮      \n",
       "551 true  57  VA     4  1    96     130      207  0   1       1     1      \n",
       "552 true  68  VA     3  1   151     134      254  1   0       1     0      \n",
       "553 true  51  VA     4  0    96     114      258  1   2       0     1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#split all the datasets into training and testing sets\n",
    "\n",
    "cleveland_split <- initial_split(cleveland_data, prop = 0.75, strata = num)\n",
    "cleveland_train <- training(cleveland_split)\n",
    "cleveland_test <- testing(cleveland_split)\n",
    "\n",
    "hungarian_split <- initial_split(hungarian_data, prop = 0.75, strata = num)\n",
    "hungarian_train <- training(hungarian_split)\n",
    "hungarian_test <- testing(hungarian_split)\n",
    "\n",
    "switzerland_split <- initial_split(switzerland_data, prop = 0.75, strata = num)\n",
    "switzerland_train <- training(switzerland_split)\n",
    "switzerland_test <- testing(switzerland_split)\n",
    "\n",
    "va_split <- initial_split(va_data, prop = 0.75, strata = num)\n",
    "va_train <- training(va_split)\n",
    "va_test <- testing(va_split)\n",
    "\n",
    "all_split <- initial_split(all_data, prop = 0.75, strata = num)\n",
    "all_train <- training(all_split)\n",
    "all_test <- testing(all_split)\n",
    "\n",
    "all_train # Table 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296e256-ecf1-4163-9e9c-246779b26dec",
   "metadata": {},
   "source": [
    "### Forward Selection: finding the best predictors\n",
    "In this cell, we write a function (written using a lot of code adapted from the textbook) which performs forward selection on a training set, which will be provided as an argument. This function then returns a tibble which lists the accuracy that results from using different combinations and numbers of predictors with the given dataframe. The specifics of this function are complex, but essentially it performs the following steps:\n",
    "\n",
    "Starting with no predictors \"used\"...\n",
    "1. try adding each of the unused predictors to the model formed by the current \"used\" predictors in turn; evaluate the accuracy of the resulting model\n",
    "2. Whichever resulting model was the most accurate, becomes the new model, and the new predictor added to it is removed from the \"unused\" predictors\n",
    "3. The process repeats until no predictors remain\n",
    "\n",
    "A human can then choose the model with the best combination of accuracy* and simplicity** \n",
    "In this case, we multiply the accuracy stat of each combination of predictors to get a value back in units of % accuracy.\n",
    "\n",
    "\\*sometimes additional predictors will *reduce* the accuracy, after a point; sometimes the best model in terms of accuracy will have so many predictors its unwieldy to predict with. That being said, forward selection should not be used with too many predictors lest is accuracy reporting become unreliable, so the latter concern is less of an issue)\n",
    "\\*\\*In the case of this project, because we are not even starting off with too many predictors, we use code to automatically pick the most accurate set of predictors and use it in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "471a1d0a-2fc4-4e95-be62-a50e5bb7cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_predictors <- function(df) {\n",
    "#!EA rename stuff from cancer to heart disease\n",
    "    cancer_subset <- df\n",
    "    names <- colnames(cancer_subset |> select(-num,-region))\n",
    "    \n",
    "    cancer_subset\n",
    "\n",
    "\n",
    "    # create an empty tibble to store the results\n",
    "    accuracies <- tibble(size = integer(), \n",
    "                         model_string = character(), \n",
    "                         accuracy = numeric())\n",
    "\n",
    "    # create a model specification\n",
    "    knn_spec <- nearest_neighbor(weight_func = \"rectangular\", \n",
    "                                 neighbors = tune()) |>\n",
    "         set_engine(\"kknn\") |>\n",
    "         set_mode(\"classification\")\n",
    "\n",
    "    # create a 5-fold cross-validation object\n",
    "    cancer_vfold <- vfold_cv(cancer_subset, v = 5, strata = num)\n",
    "\n",
    "    # store the total number of predictors\n",
    "    n_total <- length(names)\n",
    "\n",
    "    # stores selected predictors\n",
    "    selected <- c()\n",
    "\n",
    "    # for every size from 1 to the total number of predictors\n",
    "    for (i in 1:n_total) {\n",
    "        # for every predictor still not added yet\n",
    "        accs <- list()\n",
    "        models <- list()\n",
    "        for (j in 1:length(names)) {\n",
    "            # create a model string for this combination of predictors\n",
    "            preds_new <- c(selected, names[[j]])\n",
    "            model_string <- paste(\"num\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "            # create a recipe from the model string\n",
    "            cancer_recipe <- recipe(as.formula(model_string), \n",
    "                                    data = cancer_subset) |>\n",
    "                              step_scale(all_predictors()) |>\n",
    "                              step_center(all_predictors())\n",
    "\n",
    "            # tune the KNN classifier with these predictors, \n",
    "            # and collect the accuracy for the best K\n",
    "            acc <- workflow() |>\n",
    "              add_recipe(cancer_recipe) |>\n",
    "              add_model(knn_spec) |>\n",
    "              tune_grid(resamples = cancer_vfold, grid = 10) |>\n",
    "              collect_metrics() |>\n",
    "              filter(.metric == \"accuracy\") |>\n",
    "              summarize(mx = max(mean))\n",
    "            acc <- acc$mx |> unlist()\n",
    "\n",
    "            # add this result to the dataframe\n",
    "            accs[[j]] <- acc\n",
    "            models[[j]] <- model_string\n",
    "        }\n",
    "        jstar <- which.max(unlist(accs))\n",
    "        accuracies <- accuracies |> \n",
    "          add_row(size = i, \n",
    "                  model_string = models[[jstar]], \n",
    "                  accuracy = accs[[jstar]])\n",
    "        selected <- c(selected, names[[jstar]])\n",
    "        names <- names[-jstar]\n",
    "    }\n",
    "\n",
    "    accuracies <- mutate(accuracies, percent_accuracy = accuracy*100)\n",
    "\n",
    "    return(accuracies)\n",
    "\n",
    "}\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc0d49-573f-4338-987c-1587646efbc6",
   "metadata": {},
   "source": [
    "### Applying the function to calculate best predictor sets\n",
    "In the cell below we calculate the best set of predictors for each data set (excluding Switzerland, for reasons mentioned earlier), using the function we wrote above. The highest-accuracy set of predictors for each dataset is printed out. These "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9289a-28a6-4453-a3ac-c84e24ddd903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 1 × 2\u001b[39m\n",
      "  model_string                                     percent_accuracy\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                                       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m num ~ thalach+cp+oldpeak+exang+fbs+chol+trestbps             82.3\n",
      "\u001b[90m# A tibble: 1 × 2\u001b[39m\n",
      "  model_string                                           percent_accuracy\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                                             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m num ~ thalach+cp+sex+trestbps+age+oldpeak+restecg+chol             78.0\n"
     ]
    }
   ],
   "source": [
    "all_accuracy <- find_predictors(all_train)\n",
    "print(all_accuracy |> select(model_string, percent_accuracy) |> slice_max(order_by = percent_accuracy, n = 1))\n",
    "\n",
    "cleveland_accuracy <- find_predictors(cleveland_train)\n",
    "print(cleveland_accuracy |> select(model_string, percent_accuracy) |> slice_max(order_by = percent_accuracy, n = 1))\n",
    "\n",
    "hungarian_accuracy <- find_predictors(hungarian_train)\n",
    "print(hungarian_accuracy |> select(model_string, percent_accuracy) |> slice_max(order_by = percent_accuracy, n = 1))\n",
    "\n",
    "# switzerland_accuracy <- find_predictors(switzerland_train) # Note: this dataset is way too small, such that many validation sets will lack \"true\" values. Tune the filtering-out of NA values, or just don't test it.\n",
    "# print(switzerland_accuracy, n=10)\n",
    "\n",
    "va_accuracy <- find_predictors(va_train)\n",
    "print(va_accuracy |> select(model_string, percent_accuracy) |> slice_max(order_by = percent_accuracy, n = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0195c8c-7349-4bed-9743-9740c562f850",
   "metadata": {},
   "source": [
    "### Plotting the accuracy of different sets of predictors for each region\n",
    "In the following code cells, to confirm that we picked good choices for our predictor sets, we graph the number of predictors selected against the accuracy of each set of predictors. The function we write below helps speed this process up; given an accuracy dataframe of the type that is returned by the find_predictors() function we wrote, it will produce a graph of the # of predictors of each model vs the accuracy the model provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25d3be-1307-4e38-875d-71890b133ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy <- function(accur, t=\"UNDEFINED\"){\n",
    "    ggplot(accur, aes(x = size, y = percent_accuracy)) +\n",
    "        geom_point() +\n",
    "        geom_line() +\n",
    "        labs(x = \"Number of predictors\", y = \"Accuracy (%)\", title = paste(\"Percent accuracy vs # of predictors for\",t)) +\n",
    "        theme(text = element_text(size = 15))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4c216-363d-4103-a529-1522a5e96960",
   "metadata": {},
   "source": [
    "In the cell below we plot the accuracy of models trained on the super-dataset of all regions combined. The \"elbow\" appears to be at the point where the number of predictors is equal to !EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4502228-c564-4d8b-88b4-e9728e92f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(all_accuracy, \"all regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977717c-921c-409b-b4c2-17550069ef2b",
   "metadata": {},
   "source": [
    "In the cell below we plot the accuracy of models trained on the Cleveland Clinic Foundation dataset. The \"elbow\" appears to be at the point where the number of predictors is equal to !EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf684a11-3607-45d5-adee-576fc78cc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(cleveland_accuracy, \"Cleveland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211d0dd-401b-4a90-b724-09d59d460571",
   "metadata": {},
   "source": [
    "In the cell below we plot the accuracy of models trained on the University Hospital of Basel dataset. The \"elbow\" appears to be at the point where the number of predictors is equal to !EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f690e-57b4-4184-9415-47f47053666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(hungarian_accuracy, \"Hungary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caec811-cf1d-4a79-b9ad-2f5b5d802e4f",
   "metadata": {},
   "source": [
    "In the cell below we plot the accuracy of models trained on the Veterans Affairs Long Beach Medical Center dataset. The \"elbow\" appears to be at the point where the number of predictors is equal to !EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b00e1-7184-4f92-b763-8dc0a1659824",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(va_accuracy, \"VA Long Beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4e528-c607-45f2-8647-0937b10e5e27",
   "metadata": {},
   "source": [
    "Do note that while the textbook says to pick the \"elbow\" of the graph, we let our code automatically pick the model with the highest accuracy, out of concern that our relative inexperience will lead to us picking a poor elbow and compromising the accuracy of the model. # !EA maybe just delete this and take the punch and rewrite things so that we manually judge the elbow. Ahhhhh but that would suck the current way is cool. Think on it. Or maybe someone else can make the call. Ahh just do it. But later, I'm not ready yet to kill my over-engineered darling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126dab6-dadc-4f73-a1e2-94fd530cec30",
   "metadata": {},
   "source": [
    "### Checking accuracy against the testing data | the final step\n",
    "In the code cell below, we write a functioon that takes an accuracy dataframe (of the type outputted by the forward-selection function we built earlier), a training dataframe, and a testing dataframe, fits a knn classification model using the best value of \"k\", and then checks the accuracy of this fitted model against the testing set. The function returns a tuple (two-element vector) with the measured accuracy and the best value of K as elements (we will use the best value of K in a later visualization). The process here closely follows the types of problems we have done in-class, but at a high level:\n",
    "\n",
    "1. The best set of predictors is pulled from the \"accuracy\" dataframe.\n",
    "1. A recipe is created using this set of predictors; all predictors are scaled and centered\n",
    "1. A model specification is set up, with the neighbors argument equal to \"tune()\" -- we have to pick the best value of K for our model before we evaluate its accuracy.\n",
    "1. A fold object is created, with the # of folds equal to 10, for the sake of greater precision. At this point enough randomness has appeared that we want to be as precise as we can be.\n",
    "1. The model is tuned, the accuracy for each value of K collected, and the best value of K is extracted and saved to a variable\n",
    "1. Another KNN model is created, this time using the best value of K, identified in the previous steps, as its neighbors value.\n",
    "1. This KNN model is fit on the training data, and then used to predict values in the testing set.\n",
    "1. The prediction is tidied up a bit, with only the .estimate column of the \"accuracy\" observation being kept, and it being renamed to \"accuracy.\"\n",
    "1. The accuracy of the model using the best value of K, as well as this best value of K, are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd8d80-02d5-42f8-af02-c801954ba0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_fit <- function(accuracy_df, train_df, test_df, region=\"\"){\n",
    "    # get predictors with max accuracy\n",
    "    best_predictors <- accuracy_df |> slice_max(percent_accuracy, n = 1) |> pull(model_string)\n",
    "    \n",
    "    df_recipe <- recipe(as.formula(best_predictors), data = train_df) |> \n",
    "        step_scale(all_predictors()) |> \n",
    "        step_center(all_predictors())\n",
    "    \n",
    "    df_spec_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |> set_engine(\"kknn\") |> set_mode(\"classification\")\n",
    "    \n",
    "    df_fold <- vfold_cv(train_df, v = 10, strata = num)\n",
    "    \n",
    "    df_k_fit <- workflow() |>\n",
    "        add_recipe(df_recipe) |>\n",
    "        add_model(df_spec_tune) |>\n",
    "        tune_grid(resamples = df_fold, grid = 10) |>\n",
    "        collect_metrics()\n",
    "    \n",
    "    best_k <- df_k_fit |> slice_max(mean, n = 1) |> select(neighbors) |> pull()\n",
    "    print(paste(\"The best value of K for\", region, \"is\", best_k))\n",
    "    \n",
    "    df_spec_k <- nearest_neighbor(weight_func = \"rectangular\", neighbors = best_k) |> set_engine(\"kknn\") |> set_mode(\"classification\")\n",
    "    \n",
    "    df_fit <- workflow() |>\n",
    "        add_recipe(df_recipe) |>\n",
    "        add_model(df_spec_k) |>\n",
    "        fit(data = train_df)\n",
    "\n",
    "    df_summary <- df_fit |>\n",
    "        predict(test_df) |>\n",
    "        bind_cols(test_df) |>\n",
    "        metrics(truth = num, estimate = .pred_class) |>\n",
    "        filter(.metric == \"accuracy\") |>\n",
    "        select(.estimate) |>\n",
    "        rename(accuracy = .estimate)\n",
    "    return(c(df_summary,best_k)) # return the tuple so that I can access best_k in code later\n",
    "    }\n",
    "        \n",
    "# cleveland_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_and_fit(switzerland_accuracy,switzerland_train,switzerland_test, \"Switzerland\")[1] # Switzerland explodes for some reason, probably due to lack of data causing unexpected inputs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa2ca6-c930-418f-bc58-5a094407cb11",
   "metadata": {},
   "source": [
    "#### Calculating accuracy using test dataset: All\n",
    "\n",
    "In the cells below we call the function we wrote above to get the accuracy of the model (using the best set of predictors and the best K) as evaluated against the testing set. In each case we must take the first element of the tuple returned by the function, as the function's return value is of the form c(*accuracy*, *best_k*). The cell directly below this one calculates and extracts the accuracy of the model we created for the super-dataset, comprised of information from all the regions considered in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843988b0-6c0f-4a67-a0f9-32fa7ac35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mod <- model_and_fit(all_accuracy,all_train,all_test, \"all regions combined\")\n",
    "all_mod[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae4384-2804-437d-9519-8fa52e7358b2",
   "metadata": {},
   "source": [
    "#### Calculating accuracy using test dataset: Cleveland\n",
    "\n",
    "In the cell below we calculate the accuracy of the best model we can make using the data specifically from Cleveland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484eb18-8be9-4ba3-b9fc-d31bf110964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mod <- model_and_fit(cleveland_accuracy,cleveland_train,cleveland_test, \"Cleveland\")\n",
    "cl_mod[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd81f6-0cf0-4557-b871-a4908e7f672d",
   "metadata": {},
   "source": [
    "#### Calculating accuracy using test dataset: Hungary\n",
    "\n",
    "In the cell below we calculate the accuracy of the best model we can make using the data specifically from Hungary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0f347-ffba-4568-afd0-b9841c4d3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_mod <- model_and_fit(hungarian_accuracy,hungarian_train,hungarian_test, \"Hungary\")\n",
    "hu_mod[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322e28e-c0d1-4472-a9c6-d3c2dbdc1709",
   "metadata": {},
   "source": [
    "#### Calculating accuracy using test dataset: VA Long Beach\n",
    "\n",
    "In the cell below we calculate the accuracy of the best model we can make using the data specifically from VA Long Beach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a1da9-59e0-4d59-9e73-8a88950d9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_test\n",
    "va_mod <- model_and_fit(va_accuracy,va_train,va_test, \"VA Long Beach\") # This blew up the first time I tried to run it. Watch out. See if there's something off with my code or if I just somehow executed in the wrong order.\n",
    "va_mod[1]                                                              # This blew up a second time. There is 100% a problem here. There's some problem with the va_test table. Check it out. !EA !EA !EA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ceaf7-29fa-4e7a-b159-82352a6e6df7",
   "metadata": {},
   "source": [
    "## Visualization of the analysis\n",
    "In this section we use visualization to provide a more concrete interpretation of the results of our analysis. Unfortunately, because we {!EA CONFIRM THAT WE END UP WITH MORE THAN TWO PREDICTORS AFTER THE DOMAIN KNOWLEDGE SHIFT} used more than two predictors for each of our models, they are not easily graphed -- humans can only visualize things in three dimensions, and only graphs in two dimensions are truly easy to understand at a glance. This being the case, we decided to visualize the dataset and indicate the areas where a person is diagnosed with heart disease by a model that uses 2 parameters: thalach and cp !EA, which consistently, throughout all of our models for all of the different regions, appeared and played a significant role in boosting accuracy. This means we need to build a custom model for this visualization specifically. After doing this, we create a graph with \"zones of classification\" -- areas where any new points that fall in them get classified as having a certain class -- overlaid on top of the whole dataset. In this case, we are using the Cleveland dataset, because this is the dataset which produced the most accurate model during our analysis.\n",
    "\n",
    "Much of the code from the following sections was adapted from the textbook.\n",
    "\n",
    "### Part 1: Find Best K for Simplified Model\n",
    "In the following cell, we identify the best value of k for our simplified, two-parameter KNN model. The process is much the same as in the model_and_fit() function we wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa59a43-5ba6-43ca-8877-92839508c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Best K for 2 predictors\n",
    "# (Since we're unable to visualize more than 3 dimensions, we must pick only 2 predictors: I will select cp and thalach,\n",
    "# which together had pretty decent accuracy results for most of the regions)\n",
    "\n",
    "cleveland_recipe <- recipe(num ~ cp + thalach, data = cleveland_train) |> \n",
    "    step_scale(all_predictors()) |> \n",
    "    step_center(all_predictors())\n",
    " \n",
    "cl_spec_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |> set_engine(\"kknn\") |> set_mode(\"classification\")\n",
    "\n",
    "cl_fold <- vfold_cv(cleveland_train, v = 10, strata = num)\n",
    "\n",
    "cl_k_fit <- workflow() |>\n",
    "    add_recipe(cleveland_recipe) |>\n",
    "    add_model(cl_spec_tune) |>\n",
    "    tune_grid(resamples = cl_fold, grid = 10) |>\n",
    "    collect_metrics()\n",
    "\n",
    "cl_best_k <- cl_k_fit |> slice_max(mean, n = 1) |> select(neighbors) |> pull()\n",
    "\n",
    "\n",
    "\n",
    "# Interesting idea: plot the number of datapoints in a region vs the best value of K. This can be accomplished by counting the rows of each dataframe and binding these summarized tibbles.\n",
    "# Make the model_and_fit function return a tuple with the accuracy value and the best value of K so that I can pull those and bind them. Or just read the values off the output.\n",
    "# ggplot("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bed3ab-e830-4787-86eb-476c851cf18e",
   "metadata": {},
   "source": [
    "### Part 2: Fit\n",
    "\n",
    "In the next cell, we use the calculated best value of K in a new model that is fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714d514-5d41-402e-92eb-4a53f04d7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Fit\n",
    "# We're viewing cleveland because it's the most accurate. (we've also then validated the choice of past ML researchers, who used the cleveland set exclusively as well)\n",
    "\n",
    "cleveland_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = cl_best_k) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "cleveland_fit <- workflow() |>\n",
    "    add_recipe(cleveland_recipe) |>\n",
    "    add_model(cleveland_spec) |>\n",
    "    fit(data = cleveland_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74890901-a7b9-4d62-b538-66b4de20ba68",
   "metadata": {},
   "source": [
    "### Part 3: Graph\n",
    "\n",
    "In the following cell, we create a grid of artificial values that will be used in visualizing where a point has to fall to be classified as having heart disease or not. We predict the !EA num variable of each of these artificial values for this same purpose. This cell uses a lot of code adapted from the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed0923-dd45-47e9-9ee7-394ab7a5b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Predict\n",
    "# Inspired by the textbook, posted at https://canvas.ubc.ca/courses/102025/modules/items/4720443\n",
    "# Note: since we can only graph two predictors, I'm picking the two that, combined, produced decent accuracy in all examples: thalach and CP\n",
    "thal_grid <- seq(min(cleveland_train$thalach),\n",
    "                 max(cleveland_train$thalach),\n",
    "                 length.out = 100) # sets the desired length of the sequence\n",
    "cp_grid <- seq(min(cleveland_train$cp),\n",
    "                 max(cleveland_train$cp),\n",
    "                 length.out = 100) # sets the desired length of the sequence\n",
    "combined_grid <- as_tibble(expand.grid(thalach = thal_grid, cp = cp_grid)) # TODO !EA: figure out using the docs what CP is, put its name here\n",
    "\n",
    "predicted_grid <- predict(cleveland_fit, combined_grid)\n",
    "\n",
    "prediction_table <- bind_cols(predicted_grid,combined_grid) |> rename(num = .pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2614ab-1030-47fb-93ec-af04be079cf7",
   "metadata": {},
   "source": [
    "### Part 4: Graph\n",
    "In the next cell, we plot each point of the entire Cleveland dataset with the cp variable on the x axis, and the thalach variable on the y axis of a scatterplot. The predicted grid of artificial values is plotted as well, with a large size and low alpha, as a method of visualizing which locations lead to which classifications. The colors of blue and red are chosen in an attempt to be accessible to the colorblind. Each point from the original dataset is also colored based on its true value. This reveals that the cp variable equalling 4 is a good predictor for a patient having heart disease; the positive cases, and the region where new points are classified as positive, are overwhelmingly concentrated around cp = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30f224-c8ed-432a-a4d1-1658ec6a55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Graph\n",
    "ggplot() +\n",
    "    geom_point(data = cleveland_data,\n",
    "               mapping = aes(x = cp, y = thalach, color = num), alpha = 0.75) +\n",
    "    geom_point(data = prediction_table,\n",
    "               mapping = aes(x = cp, y = thalach, color = num), alpha = 0.02, size = 5) +\n",
    "    labs(color = \"Patient has heart disease\",\n",
    "         x = \"Thalach (maximum heart rate achieved)\",\n",
    "         y = \"CP (no idea what this means rn\",\n",
    "         title =\"Heart disease is strongly correlated with a CP of 4\") +\n",
    "    scale_color_manual(labels = c(\"heart disease present\", \"heart disease not present\"),\n",
    "                       values = c(\"red1\", \"steelblue1\")) +\n",
    "    theme(text = element_text(size = 15))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000e63b-0f26-4b86-926f-573d93e9c7d8",
   "metadata": {},
   "source": [
    "### Extra: See if there is a relation between number of observations and value of K\n",
    "\n",
    "As a matter of curiosity, we plotted the count of observations versus the calculated best value of K for each of the datasets we built models for (excluding the \"all\" dataset). The results were mixed. There are likely too few examples to draw any solid conclusions (3 is hardly a large sample size) but the result of the smallest of the datasets (VA Long Beach) having the lowest best K is consistent with what we know: a smaller dataset, where individual points are more significant to a given prediction, is more likely to suffer from underfitting if K is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51784ea1-5563-4135-86ab-db3646eed2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_region <- group_by(all_data, region) |> summarize(count = n())\n",
    "count_by_region <- filter(count_by_region, region != \"S\") # 'Cause Switzerland has innaccurate knn results due to low size\n",
    "count_by_region <- bind_cols(count_by_region, tibble(best_k = c(cl_mod[2],hu_mod[2],va_mod[2])))\n",
    "ggplot() +\n",
    "    geom_point(data = count_by_region, \n",
    "               mapping = aes(x = best_k, y = count, color = region), size = 5) +\n",
    "    geom_line(data = count_by_region, \n",
    "               mapping = aes(x = best_k, y = count)) +\n",
    "    labs(x = \"Best value of K for that region\", y = \"# of rows in that region\", color = \"Region\") +\n",
    "    theme(text = element_text(size = 18))\n",
    "\n",
    "# With three datapoints it's hard to draw any clear conclusions. It makes sense that a dataset with very few datapoints would work best with a low value of K, though.\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd789dd9-ffb0-4b85-9436-43158fac3a55",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "In order to decide what variables will be used as predictors for this model, we will employ forward selection, using the metric of accuracy. This will allow us to reliably determine, without assumptions, which variables contribute to improving the accuracy of the model and which do not. Because we have not yet done the analysis (and thus haven’t performed the forward selection yet) we cannot state which columns we will use at this time. To visualize the results, we will plot different choices of *k* for the model vs the accuracy that this choice of parameter produces. We will use this visualization to determine which choice of *k* results in the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aca1b3-7fa9-4b7f-9451-0deca47bf37a",
   "metadata": {},
   "source": [
    "## Expected Outcomes And Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6ae66-302c-4e33-ad3c-d99a247e1617",
   "metadata": {},
   "source": [
    "### What do you expect to find?\n",
    "\n",
    "With this data analysis, we would expect to find a correlation between whether or not an individual has a heart disease, and certain variables that we could use to predict it. For example, if an individual has a higher than average resting blood pressure, and higher than average cholesterol, we would expect for them to have a similarly higher chance of having a heart disease. This prediction is based on previous knowledge of heart diseases, but with our analysis we would expect to find some other factors that point to an individual having a higher or lower chance of contracting a heart disease. \n",
    "\n",
    "### What impact could such findings have?\n",
    "\n",
    "These findings could allow hospitals to more accurately predict if an individual has a heart disease by attempting to classify it using our data set. It could also reduce the workload of doctors and nurses by automatically calculating how likely it is for someone to have a heart disease, which could get rid of the easy diagnoses and let doctors take over for the more difficult ones. By capturing the most impactful properties that indicate heart disease, we can also attempt to figure out methods of treatment and prevention that directly influence these properties.\n",
    "\n",
    "### What future questions could this lead to?\n",
    "\n",
    "This could lead to further questions about medical diagnoses from data, and if they could ever have any real life applications in the medical field. For example, based on the properties of a mole, could we predict if it is harmful or not? On the other hand, we could also ask the question of how legitimate our model is, by using a completely different heart disease data set and comparing the accuracy. Finally, as we have access to heart disease data from a variety of locations, we could ask the question: do the characteristics of heart disease remain consistent in different regions of the world? If they do not, we could try to figure out how it is different and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c86fdf-d08d-4067-bfd9-f65759d8470a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
